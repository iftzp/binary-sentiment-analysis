{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "boxed-supplier",
   "metadata": {},
   "source": [
    "# Sentiment Polarity Prediction with Naive Bayes\n",
    "\n",
    "This notebook contains a basic implementation of document-level sentiment analysis\n",
    "for movie reviews with multinomial Naive Bayes and bag-of-words features\n",
    "and of cross-validation.\n",
    "* No special treatment of rare or unknown words. Unknown words in the test data are skipped.\n",
    "\n",
    "We use the movie review polarity data set of Pang and Lee 2004 [A Sentimental Education: Sentiment Analysis Using Subjectivity Summarization Based on Minimum Cuts](https://www.aclweb.org/anthology/P04-1035/) in Version 2.0 available from http://www.cs.cornell.edu/People/pabo/movie-review-data (section \"Sentiment polarity datasets\"). This dataset contains 1000 positive and 1000 negative reviews, each tokenised, sentence-split (one sentence per line) and lowercased. Each review has been assigned to 1 of 10 cross-validation folds by the authors and this setup should be followed to compare with published results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fitted-acting",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\carro\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\carro\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import time\n",
    "import urllib.request\n",
    "import numpy\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "data_source = 'local-folder'\n",
    "data_folder = os.path.join('data', 'txt_sentoken')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adjustable-crazy",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PL04DataLoader_Part_1:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def get_labelled_dataset(self, fold = 0):\n",
    "        ''' Compile a fold of the data set\n",
    "        '''\n",
    "        dataset = []\n",
    "        for label in ('pos', 'neg'):\n",
    "            for document in self.get_documents(\n",
    "                fold = fold,\n",
    "                label = label,\n",
    "            ):\n",
    "                dataset.append((document, label))\n",
    "        return dataset\n",
    "    \n",
    "    def get_documents(self, fold = 0, label = 'pos'):\n",
    "        ''' Enumerate the raw contents of all data set files.\n",
    "            Args:\n",
    "                data_dir: relative or absolute path to the data set folder\n",
    "                fold: which fold to load (0 to n_folds-1)\n",
    "                label: 'pos' or 'neg' to\n",
    "                    select data with positive or negative sentiment\n",
    "                    polarity\n",
    "            Return:\n",
    "                List of tokenised documents, each a list of sentences\n",
    "                that in turn are lists of tokens\n",
    "        '''\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "happy-civilization",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PL04DataLoader(PL04DataLoader_Part_1):\n",
    "    \n",
    "    def get_xval_splits(self):\n",
    "        ''' Split data with labels for cross-validation\n",
    "            returns a list of k pairs (training_data, test_data)\n",
    "            for k cross-validation\n",
    "        '''\n",
    "        # load the folds\n",
    "        folds = []\n",
    "        for i in range(10):\n",
    "            folds.append(self.get_labelled_dataset(\n",
    "                fold = i\n",
    "            ))\n",
    "        # create training-test splits\n",
    "        retval = []\n",
    "        for i in range(10):\n",
    "            test_data = folds[i]\n",
    "            training_data = []\n",
    "            for j in range(9):\n",
    "                ij1 = (i+j+1) % 10\n",
    "                assert ij1 != i\n",
    "                training_data = training_data + folds[ij1]\n",
    "            retval.append((training_data, test_data))\n",
    "        return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "enabling-original",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PL04DataLoaderFromStream(PL04DataLoader):\n",
    "        \n",
    "    def __init__(self, tgz_stream, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.data = {}\n",
    "        counter = 0\n",
    "        with tarfile.open(\n",
    "            mode = 'r|gz',\n",
    "            fileobj = tgz_stream\n",
    "        ) as tar_archive:\n",
    "            for tar_member in tar_archive:\n",
    "                if counter == 2000:\n",
    "                    break\n",
    "                path_components = tar_member.name.split('/')\n",
    "                filename = path_components[-1]\n",
    "                if filename.startswith('cv') \\\n",
    "                and filename.endswith('.txt') \\\n",
    "                and '_' in filename:\n",
    "                    label = path_components[-2]\n",
    "                    fold = int(filename[2])\n",
    "                    key = (fold, label)\n",
    "                    if key not in self.data:\n",
    "                        self.data[key] = []\n",
    "                    f = tar_archive.extractfile(tar_member)\n",
    "                    document = [\n",
    "                        line.decode('utf-8').split()\n",
    "                        for line in f.readlines()\n",
    "                    ]\n",
    "                    self.data[key].append(document)\n",
    "                    counter += 1\n",
    "            \n",
    "    def get_documents(self, fold = 0, label = 'pos'):\n",
    "        return self.data[(fold, label)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chinese-cooper",
   "metadata": {},
   "source": [
    "## Read Data from the Web\n",
    "This should run efficiently both on google colab and locally but has the disadvantage that the same data is downloaded each time the notebook is run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "medical-enterprise",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PL04DataLoaderFromURL(PL04DataLoaderFromStream):\n",
    "    \n",
    "    def __init__(self, data_url, **kwargs):\n",
    "        with urllib.request.urlopen(data_url) as tgz_stream:\n",
    "            super().__init__(tgz_stream, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forced-domestic",
   "metadata": {},
   "source": [
    "## Read Data from a Local .tgz File\n",
    "\n",
    "You manually download the .tgz once to a filesystem that can be accessed from the notebook, e.g. google drive on colab, and this notebook reads this file in one chunk. \n",
    "\n",
    "Note that if you are accessing files from google drive on colab, you will need to mount your drive and enter an authentication token:\n",
    "\n",
    "```\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "```\n",
    "\n",
    "You will also have to change your *data_tgz* or *data_folder* paths above so that they start with *'/content/drive/My Drive/'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "affecting-footage",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PL04DataLoaderFromTGZ(PL04DataLoaderFromStream):\n",
    "    \n",
    "    def __init__(self, data_path, **kwargs):\n",
    "        with open(data_path, 'rb') as tgz_stream:\n",
    "            super().__init__(tgz_stream, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vital-capability",
   "metadata": {},
   "source": [
    "## Read Data from a Local Folder\n",
    "\n",
    "Extract the .tgz to a local folder and only load the required files. This is usually the fastest option when storage is on a local SSD. On remote filesystems, however, this can be very slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "vocational-chase",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PL04DataLoaderFromFolder(PL04DataLoader):\n",
    "    \n",
    "    def __init__(self, data_dir, **kwargs):\n",
    "        self.data_dir = data_dir\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "    def get_documents(self, fold = 0, label = 'pos'):\n",
    "        # read folder contents\n",
    "        path = os.path.join(self.data_dir, label)\n",
    "        dir_entries = os.listdir(path)\n",
    "        # must process entries in numeric order to\n",
    "        # replicate order of original experiments\n",
    "        dir_entries.sort()\n",
    "        # check each entry and add to data if matching\n",
    "        # selection criteria\n",
    "        for filename in dir_entries:\n",
    "            if filename.startswith('cv') \\\n",
    "            and filename.endswith('.txt'):\n",
    "                if fold == int(filename[2]):\n",
    "                    # correct fold\n",
    "                    f = open(os.path.join(path, filename), 'rt')\n",
    "                    # \"yield\" tells Python to return an iterator\n",
    "                    # object that produces the yields of this\n",
    "                    # function as elements without creating a\n",
    "                    # full list of all elements\n",
    "                    yield [line.split() for line in f.readlines()]\n",
    "                    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "moved-pharmacology",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_source == 'local-folder':\n",
    "    data_loader = PL04DataLoaderFromFolder(data_folder)\n",
    "elif data_source == 'local-tgz':\n",
    "    data_loader = PL04DataLoaderFromTGZ(data_tgz)\n",
    "elif data_source == 'web':\n",
    "    data_loader = PL04DataLoaderFromURL(data_url)\n",
    "else:\n",
    "    raise ValueError('Unsupported data source %r' %data_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "guilty-kitchen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== pos ==\n",
      "doc sentences start of first sentence\n",
      "  0      25   films|adapted|from|comic|books|have|had|plenty|of|success|,|whether\n",
      "  1      39   every|now|and|then|a|movie|comes|along|from|a|suspect|studio|,|with\n",
      "  2      19   you've|got|mail|works|alot|better|than|it|deserves|to|.|in|order|to|make\n",
      "  3      42   \"|jaws|\"|is|a|rare|film|that|grabs|your|attention|before|it|shows|you|a\n",
      "  4      25   moviemaking|is|a|lot|like|being|the|general|manager|of|an|nfl|team|in\n",
      "== neg ==\n",
      "doc sentences start of first sentence\n",
      "  0      35   plot|:|two|teen|couples|go|to|a|church|party|,|drink|and|then|drive|.\n",
      "  1      13   the|happy|bastard's|quick|movie|review|damn|that|y2k|bug|.|it's|got|a\n",
      "  2      23   it|is|movies|like|these|that|make|a|jaded|movie|viewer|thankful|for|the\n",
      "  3      19   \"|quest|for|camelot|\"|is|warner|bros|.|'|first|feature-length|,\n",
      "  4      37   synopsis|:|a|mentally|unstable|man|undergoing|psychotherapy|saves|a|boy\n"
     ]
    }
   ],
   "source": [
    "def get_document_preview(document, max_length = 72):\n",
    "    s = []\n",
    "    count = 0\n",
    "    reached_limit = False\n",
    "    for sentence in document:\n",
    "        for token in sentence:\n",
    "            if count + len(token) + len(s) > max_length:\n",
    "                reached_limit = True\n",
    "                break\n",
    "            s.append(token)\n",
    "            count += len(token)\n",
    "        if reached_limit:\n",
    "            break\n",
    "    return '|'.join(s)\n",
    "    \n",
    "for label in 'pos neg'.split():\n",
    "    print(f'== {label} ==')\n",
    "    print('doc sentences start of first sentence')\n",
    "    for index, document in enumerate(data_loader.get_documents(\n",
    "        label = label\n",
    "    )):\n",
    "        print('%3d %7d   %s' %(\n",
    "            index, len(document), get_document_preview(document)\n",
    "        ))\n",
    "        if index == 4:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "short-edward",
   "metadata": {},
   "source": [
    "## Create Training-Test Splits for Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "artistic-tours",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tr-size te-size (number of documents)\n",
      "   1800     200\n",
      "   1800     200\n",
      "   1800     200\n",
      "   1800     200\n",
      "   1800     200\n",
      "   1800     200\n",
      "   1800     200\n",
      "   1800     200\n",
      "   1800     200\n",
      "   1800     200\n"
     ]
    }
   ],
   "source": [
    "splits = data_loader.get_xval_splits()\n",
    "\n",
    "print('tr-size te-size (number of documents)')\n",
    "for xval_tr_data, xval_te_data in splits:\n",
    "    print('%7d %7d' %(len(xval_tr_data), len(xval_te_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mounted-attribute",
   "metadata": {},
   "source": [
    "# Interface for Sentiment Polarity Predictor\n",
    "Let's define a base class to clarify how we plan to use polarity predictors. Its functions will have to be implemented in sub-classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "electronic-scottish",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolarityPredictorInterface:\n",
    "\n",
    "    def train(self, data_with_labels):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def predict(self, data):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "understanding-sweden",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolarityPredictorInit(PolarityPredictorInterface):\n",
    "    \n",
    "    def train(self, data_with_labels, feature):\n",
    "        \"\"\"\n",
    "        Function which trains model. Extracts features from extract_features function\n",
    "        (changes for different features). Gets targets also and passes both to training function.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Initialise vocab set object\n",
    "        self.reset_feature_sets()\n",
    "        # negate first then remove stop words? probably makes most sense\n",
    "        if self.lemmatise:\n",
    "            self.lemmatise_data(data_with_labels)\n",
    "        \n",
    "        if self.negation:\n",
    "            self.add_negation_to_data(data_with_labels)\n",
    "            \n",
    "        if self.remove_stopwords:\n",
    "            self.get_stopwords()\n",
    "            self.remove_stopwords_from_data(data_with_labels)\n",
    "            \n",
    "        # Populate with the data\n",
    "        self.add_to_feature_sets_from_data(data_with_labels)\n",
    "        \n",
    "        self.finalise_vocab()\n",
    "        tr_features = self.extract_features(data_with_labels, feature)\n",
    "        tr_targets = self.get_targets(data_with_labels)\n",
    "        self.train_model_on_features(tr_features, tr_targets)\n",
    "\n",
    "    def reset_feature_sets(self):\n",
    "        \"\"\"\n",
    "        Initialises a set to hold each of the feature sets.\n",
    "        \"\"\"\n",
    "        self.vocab = set()\n",
    "        self.bigrams = set()\n",
    "        self.trigrams = set()\n",
    "\n",
    "    def lemmatise_data(self, data):\n",
    "        \"\"\"\n",
    "        Function which lemmatises each token in the dataset.\n",
    "        \"\"\"\n",
    "        lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "        for document, label in data:\n",
    "            for sentence in document:\n",
    "                for index, token in enumerate(sentence):\n",
    "                    sentence[index] = lemmatizer.lemmatize(token)\n",
    "    \n",
    "    def add_negation_to_data(self, data):\n",
    "        \"\"\"\n",
    "        Function which negates words which follow not, no or 'n't'.\n",
    "        \"\"\"\n",
    "        for document, label in data:\n",
    "            for sentence in document:\n",
    "                negate = False\n",
    "                for index, token in enumerate(sentence):\n",
    "                    if token in ('not', 'no') or (token[-3:] == \"n't\"):\n",
    "                        negate = True\n",
    "                        continue\n",
    "                    if token == '.':\n",
    "                        negate = False\n",
    "                    if negate:\n",
    "                        sentence[index] = 'NOT_' + token\n",
    "    \n",
    "    def remove_stopwords_from_data(self, data):\n",
    "        \"\"\"\n",
    "        Function which removes stop words from the dataset.\n",
    "        \"\"\"\n",
    "        for document, label in data:\n",
    "            for sentence in document:\n",
    "                stopword_indices = []\n",
    "                for index, token in enumerate(sentence):\n",
    "                    if token in self.stopwords:\n",
    "                        stopword_indices.append(index)\n",
    "                stopword_indices.reverse()\n",
    "                for index in stopword_indices:\n",
    "                    del sentence[index]\n",
    "    \n",
    "    def get_stopwords(self):\n",
    "        self.stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "        \n",
    "    def add_to_feature_sets_from_data(self, data):\n",
    "        \"\"\"\n",
    "        Parses tokens in data and adds them to each feature set.\n",
    "        \"\"\"\n",
    "        for document, label in data:\n",
    "            for sentence in document:\n",
    "#                 sentence.insert(0, '<s>')\n",
    "#                 sentence.append('</s>')\n",
    "                prev_token = None\n",
    "                for index, token in enumerate(sentence):\n",
    "                    self.vocab.add(token)\n",
    "                    if index > 0:\n",
    "                        bigram = (prev_token, token)\n",
    "                        self.bigrams.add(bigram)\n",
    "                    if index > 1:\n",
    "                        trigram = (prev_prev_token, prev_token, token)\n",
    "                        self.trigrams.add(trigram)\n",
    "                    prev_prev_token = prev_token\n",
    "                    prev_token = token\n",
    "                        \n",
    "    def finalise_vocab(self):\n",
    "        \"\"\"\n",
    "        Creates a dict for the feature sets for faster operations.\n",
    "        \"\"\"\n",
    "        self.vocab = list(self.vocab)\n",
    "        # create reverse map for fast token lookup\n",
    "        self.vocab2index = {}\n",
    "        for index, token in enumerate(self.vocab):\n",
    "            self.vocab2index[token] = index\n",
    "            \n",
    "        self.bigrams = list(self.bigrams)\n",
    "        # create reverse map for fast token lookup\n",
    "        self.bigram2index = {}\n",
    "        for index, token in enumerate(self.bigrams):\n",
    "            self.bigram2index[token] = index\n",
    "            \n",
    "        self.trigrams = list(self.trigrams)\n",
    "        # create reverse map for fast token lookup\n",
    "        self.trigram2index = {}\n",
    "        for index, token in enumerate(self.trigrams):\n",
    "            self.trigram2index[token] = index\n",
    "        \n",
    "        \n",
    "    def extract_features(self, data, feature):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def get_targets(self, data, label2index = None):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def train_model_on_features(self, tr_features, tr_targets):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acoustic-stroke",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolarityPredictorExtractFeatures(PolarityPredictorInit):\n",
    "    \n",
    "    def __init__(self, clip_counts = True, negation=False, remove_stopwords=False, lemmatise=False, learning_model=MultinomialNB()):\n",
    "        self.clip_counts = clip_counts\n",
    "        self.negation = negation\n",
    "        self.remove_stopwords = remove_stopwords\n",
    "        self.model = learning_model\n",
    "        self.lemmatise = lemmatise\n",
    "        \n",
    "    def extract_features(self, data, ngram):\n",
    "        \"\"\"\n",
    "        Creates features from the data. This implementation creates a dict which contains the relevant feature\n",
    "        matrices for different feature implementations.\n",
    "        \"\"\"\n",
    "        feature_matrices = {}            \n",
    "#         for feature in ['bow', 'bob', 'bot']:\n",
    "        rows = len(data)\n",
    "        # Initialise a feature matrix with zeros\n",
    "        feature_matrices['bow'] = numpy.zeros((rows, len(self.vocab)), dtype=numpy.int32)\n",
    "        feature_matrices['bob'] = numpy.zeros((rows, len(self.bigrams)), dtype=numpy.int32)\n",
    "        feature_matrices['bot'] = numpy.zeros((rows, len(self.trigrams)), dtype=numpy.int32)\n",
    "        # populate feature matrix\n",
    "        for row, item in enumerate(data):\n",
    "            document, _ = item\n",
    "            for sentence in document:\n",
    "#                     if sentence[0] != '<s>':\n",
    "#                         sentence.insert(0, '<s>')\n",
    "#                     if sentence[-1] != '</s>':\n",
    "#                         sentence.append('</s>')\n",
    "                prev_token = None\n",
    "                for idx, token in enumerate(sentence):\n",
    "                    # word\n",
    "                    try:\n",
    "                        bow_index = self.vocab2index[token]\n",
    "                    except KeyError:\n",
    "                        continue\n",
    "                    if self.clip_counts:\n",
    "                        feature_matrices['bow'][row, bow_index] = 1\n",
    "                    else:\n",
    "                        feature_matrices['bow'][row, bow_index] += 1\n",
    "                    # bigram\n",
    "                    if idx > 0:\n",
    "                        bigram = (prev_token, token)\n",
    "                        try:\n",
    "                            bob_index = self.bigram2index[bigram]\n",
    "                        except KeyError:\n",
    "                            continue\n",
    "                        if self.clip_counts:\n",
    "                            feature_matrices['bob'][row, bob_index] = 1\n",
    "                        else:\n",
    "                            feature_matrices['bob'][row, bob_index] += 1\n",
    "                    # trigram\n",
    "                    if idx > 1:\n",
    "                        trigram = (prev_prev_token, prev_token, token)\n",
    "                        try:\n",
    "                            bot_index = self.trigram2index[trigram]\n",
    "                        except KeyError:\n",
    "                            continue\n",
    "                        if self.clip_counts:\n",
    "                            feature_matrices['bot'][row, bot_index] = 1\n",
    "                        else:\n",
    "                            feature_matrices['bot'][row, bot_index] += 1\n",
    "\n",
    "                    prev_prev_token = prev_token\n",
    "                    prev_token = token\n",
    "        if ngram == 'bow':\n",
    "            return feature_matrices['bow']\n",
    "        if ngram == 'bob':\n",
    "            return feature_matrices['bob']\n",
    "        if ngram == 'bot':\n",
    "            return feature_matrices['bot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "excess-sequence",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolarityPredictorAssignTargets(PolarityPredictorExtractFeatures):\n",
    " \n",
    "    def get_targets(self, data):\n",
    "        ''' create column vector with target labels\n",
    "        '''\n",
    "        # prepare target vector\n",
    "        targets = numpy.zeros(len(data), dtype=numpy.int8)\n",
    "        index = 0\n",
    "        for _, label in data:\n",
    "            if label == 'pos':\n",
    "                targets[index] = 1\n",
    "            index += 1\n",
    "        return targets\n",
    "\n",
    "    def train_model_on_features(self, tr_features, tr_targets):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "human-minutes",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolarityPredictor(PolarityPredictorAssignTargets):\n",
    "\n",
    "    def train_model_on_features(self, tr_features, tr_targets):\n",
    "        # pass numpy array to sklearn to train \n",
    "        self.model.fit(tr_features, tr_targets)\n",
    "        \n",
    "    def predict(self, data, feature, get_accuracy = False, get_confusion_matrix = False):\n",
    "        if self.lemmatise:\n",
    "            self.lemmatise_data(data)\n",
    "        if self.negation:\n",
    "            self.add_negation_to_data(data)\n",
    "        if self.remove_stopwords:\n",
    "            self.remove_stopwords_from_data(data)\n",
    "\n",
    "        # Extract features from unseen data\n",
    "        features = self.extract_features(data, feature)\n",
    "        # use numpy to get predictions\n",
    "        y_pred = self.model.predict(features)\n",
    "        # restore labels\n",
    "        labels = []\n",
    "        for is_positive in y_pred:\n",
    "            if is_positive:\n",
    "                labels.append('pos')\n",
    "            else:\n",
    "                labels.append('neg')\n",
    "        if get_accuracy or get_confusion_matrix:\n",
    "            retval = []\n",
    "            retval.append(labels)\n",
    "            y_true = self.get_targets(data)\n",
    "            if get_accuracy:\n",
    "                retval.append(\n",
    "                    metrics.accuracy_score(y_true, y_pred)\n",
    "                )\n",
    "            if get_confusion_matrix:\n",
    "                retval.append(\n",
    "                    metrics.confusion_matrix(y_true, y_pred)\n",
    "                )\n",
    "            return retval\n",
    "        else:\n",
    "            return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hourly-volleyball",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quality-puzzle",
   "metadata": {},
   "source": [
    "## Evaluation Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "critical-health",
   "metadata": {},
   "source": [
    "Our model builds three different feature representations from the input data:\n",
    "* Bag-of-Words (Unigrams)\n",
    "* Bag-of-Bigrams\n",
    "* Bag-of-Trigrams\n",
    "\n",
    "The *PolarityPredictor* model takes in a *feature* parameter which specifies which feature set of the above to use. There is also a *learning_model* parameter which specifies which particular learning model to use.\n",
    "\n",
    "The model can also be tweaked to perform the following:\n",
    "* Clip Counts in feature matrices\n",
    "* Negation\n",
    "* Removal of StopWords\n",
    "* Lemmatisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proof-breed",
   "metadata": {},
   "source": [
    "We plan to run many different experiments using different feature representations and different learning models.   Therefore, having an evaluation table which contains the details of each experiment and the corresponding evalation results will be useful. \n",
    "The following values will be recorded in the dataframe for each model:\n",
    "* Average 10 Fold Cross-Validation Accuracy\n",
    "* Root Mean Square Error (RMSE)\n",
    "* Minimum Accuracy\n",
    "* Maximum Accuracy\n",
    "\n",
    "Below, we define table to store these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "collect-fundamentals",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_dataframes = {}\n",
    "evaluation_dataframes['MultinomialNB'] = pd.DataFrame(columns=['name', 'learning_model', 'features', 'clip_counts', 'negation', 'remove_stopwords', 'lemmatise', 'avg_cv_acc', 'rmse', 'min_acc', 'max_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "composed-handling",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, splits, feature, verbose = False):\n",
    "    accuracies = []\n",
    "    fold = 0\n",
    "    for tr_data, te_data in splits:\n",
    "        if verbose:\n",
    "            print('Evaluating fold %d of %d' %(fold+1, len(splits)))\n",
    "            fold += 1\n",
    "        model.train(tr_data, feature)\n",
    "        _, accuracy = model.predict(te_data, feature, get_accuracy = True)\n",
    "        accuracies.append(accuracy)\n",
    "        if verbose:\n",
    "            print('-->', accuracy)\n",
    "    n = float(len(accuracies))\n",
    "    avg = sum(accuracies) / n\n",
    "    mse = sum([(x-avg)**2 for x in accuracies]) / n\n",
    "    return (avg, mse**0.5, min(accuracies),\n",
    "            max(accuracies))\n",
    "\n",
    "def print_first_predictions(model, te_data, feature, n = 12):\n",
    "    predictions = model.predict(te_data, feature)\n",
    "    for i in range(n):\n",
    "        document, label = te_data[i]\n",
    "        prediction = predictions[i]\n",
    "        print('%4d %s %s %s' %(i, label, prediction, get_document_preview(document),))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sufficient-collaboration",
   "metadata": {},
   "source": [
    "# 1. Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "romantic-foster",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_model = MultinomialNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bigger-decision",
   "metadata": {},
   "source": [
    "## 1.1 Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coral-helicopter",
   "metadata": {},
   "source": [
    "We run the baseline approach as a functionality test. The settings used are listed in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "approximate-madison",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_counts = True\n",
    "negation = False\n",
    "remove_stopwords = False\n",
    "lemmatise = False\n",
    "feature = 'bow' #bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "trying-sensitivity",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fold 1 of 10\n",
      "--> 0.795\n",
      "Evaluating fold 2 of 10\n",
      "--> 0.84\n",
      "Evaluating fold 3 of 10\n",
      "--> 0.84\n",
      "Evaluating fold 4 of 10\n",
      "--> 0.825\n",
      "Evaluating fold 5 of 10\n",
      "--> 0.835\n",
      "Evaluating fold 6 of 10\n",
      "--> 0.83\n",
      "Evaluating fold 7 of 10\n",
      "--> 0.84\n",
      "Evaluating fold 8 of 10\n",
      "--> 0.845\n",
      "Evaluating fold 9 of 10\n",
      "--> 0.785\n",
      "Evaluating fold 10 of 10\n",
      "--> 0.855\n"
     ]
    }
   ],
   "source": [
    "model = PolarityPredictor(clip_counts, negation, remove_stopwords, lemmatise, learning_model)\n",
    "model.train(splits[0][0], feature)\n",
    "\n",
    "baseline_avg, baseline_rmse, baseline_min_acc, baseline_max_acc = evaluate_model(model, splits, feature, verbose = True)\n",
    "evaluation_dataframes['MultinomialNB'].loc[0] = ['baseline-NB-BoW-clip', learning_model, feature, clip_counts, negation, remove_stopwords, lemmatise, baseline_avg, baseline_rmse, baseline_min_acc, baseline_max_acc]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statewide-christian",
   "metadata": {},
   "source": [
    "So, the baseline approach achieves an average accuracy score of 82.4% and has been to our evaluation table. The format of this dataframe can be seen below,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "important-relay",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MultinomialNB':                    name   learning_model features clip_counts negation  \\\n",
       " 0  baseline-NB-BoW-clip  MultinomialNB()      bow        True    False   \n",
       " \n",
       "   remove_stopwords lemmatise  avg_cv_acc      rmse  min_acc  max_acc  \n",
       " 0            False     False       0.829  0.021071    0.785    0.855  }"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smart-despite",
   "metadata": {},
   "source": [
    "## 1.2 Parameter Experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scheduled-adventure",
   "metadata": {},
   "source": [
    "We will now run experiments using the MultinomialNB model with different parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dependent-refund",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 1\n",
    "for feature in ['bow', 'bob', 'bot']:\n",
    "    for clip_counts in (True, False):\n",
    "        for negation in (True, False):\n",
    "            for remove_stopwords in (True, False):\n",
    "                for lemmatise in (True, False):\n",
    "                    model = PolarityPredictor(clip_counts, negation, remove_stopwords, lemmatise, learning_model)\n",
    "                    avg, rmse, min_acc, max_acc = evaluate_model(model, splits, feature, verbose = False)\n",
    "                    evaluation_dataframes['MultinomialNB'].loc[evaluation_dataframes['MultinomialNB'].index.max()+1] = [f'param-exp-NB-{index}', learning_model, feature, clip_counts, \n",
    "                                                                      negation, remove_stopwords, lemmatise, avg, rmse, min_acc, max_acc]\n",
    "                    index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "traditional-advisory",
   "metadata": {},
   "source": [
    "# 2. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "false-division",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_dataframes['LogisticRegression'] = pd.DataFrame(columns=['name', 'learning_model', 'features', 'clip_counts', 'negation', 'remove_stopwords', 'lemmatise', 'avg_cv_acc', 'rmse', 'min_acc', 'max_acc'])\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "learning_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ordinary-lighter",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_counts = True\n",
    "negation = False\n",
    "remove_stopwords = False\n",
    "lemmatise = False\n",
    "feature = 'bow' #bag of words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compact-advocacy",
   "metadata": {},
   "source": [
    "## 2.1 Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "north-induction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fold 1 of 10\n",
      "--> 0.82\n",
      "Evaluating fold 2 of 10\n",
      "--> 0.845\n",
      "Evaluating fold 3 of 10\n",
      "--> 0.865\n",
      "Evaluating fold 4 of 10\n",
      "--> 0.84\n",
      "Evaluating fold 5 of 10\n",
      "--> 0.875\n",
      "Evaluating fold 6 of 10\n",
      "--> 0.855\n",
      "Evaluating fold 7 of 10\n",
      "--> 0.855\n",
      "Evaluating fold 8 of 10\n",
      "--> 0.845\n",
      "Evaluating fold 9 of 10\n",
      "--> 0.83\n",
      "Evaluating fold 10 of 10\n",
      "--> 0.9\n"
     ]
    }
   ],
   "source": [
    "model = PolarityPredictor(clip_counts, negation, remove_stopwords, lemmatise, learning_model)\n",
    "model.train(splits[0][0], feature)\n",
    "\n",
    "baseline_avg, baseline_rmse, baseline_min_acc, baseline_max_acc = evaluate_model(model, splits, feature, verbose = True)\n",
    "evaluation_dataframes['LogisticRegression'].loc[0] = ['baseline-LR-BoW-clip', learning_model, feature, clip_counts, negation, remove_stopwords, lemmatise, baseline_avg, baseline_rmse, baseline_min_acc, baseline_max_acc]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "armed-novel",
   "metadata": {},
   "source": [
    "## 2.2 Parameter Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "activated-discipline",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "index = 1\n",
    "for feature in ['bow', 'bob', 'bot']:\n",
    "    for clip_counts in (True, False):\n",
    "        for negation in (True, False):\n",
    "            for remove_stopwords in (True, False):\n",
    "                for lemmatise in (True, False):\n",
    "                    model = PolarityPredictor(clip_counts, negation, remove_stopwords, lemmatise, learning_model)\n",
    "                    avg, rmse, min_acc, max_acc = evaluate_model(model, splits, feature, verbose = False)\n",
    "                    evaluation_dataframes['LogisticRegression'].loc[evaluation_dataframes['LogisticRegression'].index.max()+1] = [f'param-exp-LR-{index}', learning_model, feature, clip_counts, \n",
    "                                                                      negation, remove_stopwords, lemmatise, avg, rmse, min_acc, max_acc]\n",
    "                    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "computational-control",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>learning_model</th>\n",
       "      <th>features</th>\n",
       "      <th>clip_counts</th>\n",
       "      <th>negation</th>\n",
       "      <th>remove_stopwords</th>\n",
       "      <th>lemmatise</th>\n",
       "      <th>avg_cv_acc</th>\n",
       "      <th>rmse</th>\n",
       "      <th>min_acc</th>\n",
       "      <th>max_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline-NB-BoW-clip</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>bow</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.8290</td>\n",
       "      <td>0.021071</td>\n",
       "      <td>0.785</td>\n",
       "      <td>0.855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>param-exp-NB-1</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>bow</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.8245</td>\n",
       "      <td>0.020427</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>param-exp-NB-2</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>bow</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.8245</td>\n",
       "      <td>0.020427</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>param-exp-NB-3</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>bow</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.8245</td>\n",
       "      <td>0.020427</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>param-exp-NB-4</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>bow</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.8245</td>\n",
       "      <td>0.020427</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>param-exp-NB-5</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>bow</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.8245</td>\n",
       "      <td>0.020427</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>param-exp-NB-6</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>bow</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.8245</td>\n",
       "      <td>0.020427</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>param-exp-NB-7</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>bow</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.8245</td>\n",
       "      <td>0.020427</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>param-exp-NB-8</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>bow</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.8245</td>\n",
       "      <td>0.020427</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>param-exp-NB-9</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>bow</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.8090</td>\n",
       "      <td>0.034191</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>param-exp-NB-10</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>bow</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.8090</td>\n",
       "      <td>0.034191</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>param-exp-NB-11</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>bow</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.8090</td>\n",
       "      <td>0.034191</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>param-exp-NB-12</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>bow</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.8090</td>\n",
       "      <td>0.034191</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>param-exp-NB-13</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>bow</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.8090</td>\n",
       "      <td>0.034191</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>param-exp-NB-14</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>bow</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.8090</td>\n",
       "      <td>0.034191</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>param-exp-NB-15</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>bow</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.8090</td>\n",
       "      <td>0.034191</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>param-exp-NB-16</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>bow</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.8090</td>\n",
       "      <td>0.034191</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>param-exp-NB-17</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>bob</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.7610</td>\n",
       "      <td>0.017436</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>param-exp-NB-18</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>bob</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.7610</td>\n",
       "      <td>0.017436</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>param-exp-NB-19</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>bob</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.7610</td>\n",
       "      <td>0.017436</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>param-exp-NB-20</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>bob</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.7610</td>\n",
       "      <td>0.017436</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>param-exp-NB-21</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>bob</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.7610</td>\n",
       "      <td>0.017436</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>param-exp-NB-22</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>bob</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.7610</td>\n",
       "      <td>0.017436</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>param-exp-NB-23</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>bob</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.7610</td>\n",
       "      <td>0.017436</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>param-exp-NB-24</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>bob</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.7610</td>\n",
       "      <td>0.017436</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>param-exp-NB-25</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>bob</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.7415</td>\n",
       "      <td>0.024088</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>param-exp-NB-26</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>bob</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.7415</td>\n",
       "      <td>0.024088</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>param-exp-NB-27</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>bob</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.7415</td>\n",
       "      <td>0.024088</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>param-exp-NB-28</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>bob</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.7415</td>\n",
       "      <td>0.024088</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>param-exp-NB-29</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>bob</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.7415</td>\n",
       "      <td>0.024088</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>param-exp-NB-30</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>bob</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.7415</td>\n",
       "      <td>0.024088</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>param-exp-NB-31</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>bob</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.7415</td>\n",
       "      <td>0.024088</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>param-exp-NB-32</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>bob</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.7415</td>\n",
       "      <td>0.024088</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>param-exp-NB-33</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>bot</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6755</td>\n",
       "      <td>0.037111</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>param-exp-NB-34</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>bot</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.6755</td>\n",
       "      <td>0.037111</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>param-exp-NB-35</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>bot</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6755</td>\n",
       "      <td>0.037111</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>param-exp-NB-36</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>bot</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.6755</td>\n",
       "      <td>0.037111</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>param-exp-NB-37</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>bot</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6755</td>\n",
       "      <td>0.037111</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>param-exp-NB-38</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>bot</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.6755</td>\n",
       "      <td>0.037111</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>param-exp-NB-39</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>bot</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6755</td>\n",
       "      <td>0.037111</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>param-exp-NB-40</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>bot</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.6755</td>\n",
       "      <td>0.037111</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>param-exp-NB-41</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>bot</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6670</td>\n",
       "      <td>0.035014</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>param-exp-NB-42</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>bot</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.6670</td>\n",
       "      <td>0.035014</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>param-exp-NB-43</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>bot</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6670</td>\n",
       "      <td>0.035014</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>param-exp-NB-44</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>bot</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.6670</td>\n",
       "      <td>0.035014</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>param-exp-NB-45</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>bot</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6670</td>\n",
       "      <td>0.035014</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>param-exp-NB-46</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>bot</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.6670</td>\n",
       "      <td>0.035014</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>param-exp-NB-47</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>bot</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6670</td>\n",
       "      <td>0.035014</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>param-exp-NB-48</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>bot</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.6670</td>\n",
       "      <td>0.035014</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name   learning_model features clip_counts negation  \\\n",
       "0   baseline-NB-BoW-clip  MultinomialNB()      bow        True    False   \n",
       "1         param-exp-NB-1  MultinomialNB()      bow        True     True   \n",
       "2         param-exp-NB-2  MultinomialNB()      bow        True     True   \n",
       "3         param-exp-NB-3  MultinomialNB()      bow        True     True   \n",
       "4         param-exp-NB-4  MultinomialNB()      bow        True     True   \n",
       "5         param-exp-NB-5  MultinomialNB()      bow        True    False   \n",
       "6         param-exp-NB-6  MultinomialNB()      bow        True    False   \n",
       "7         param-exp-NB-7  MultinomialNB()      bow        True    False   \n",
       "8         param-exp-NB-8  MultinomialNB()      bow        True    False   \n",
       "9         param-exp-NB-9  MultinomialNB()      bow       False     True   \n",
       "10       param-exp-NB-10  MultinomialNB()      bow       False     True   \n",
       "11       param-exp-NB-11  MultinomialNB()      bow       False     True   \n",
       "12       param-exp-NB-12  MultinomialNB()      bow       False     True   \n",
       "13       param-exp-NB-13  MultinomialNB()      bow       False    False   \n",
       "14       param-exp-NB-14  MultinomialNB()      bow       False    False   \n",
       "15       param-exp-NB-15  MultinomialNB()      bow       False    False   \n",
       "16       param-exp-NB-16  MultinomialNB()      bow       False    False   \n",
       "17       param-exp-NB-17  MultinomialNB()      bob        True     True   \n",
       "18       param-exp-NB-18  MultinomialNB()      bob        True     True   \n",
       "19       param-exp-NB-19  MultinomialNB()      bob        True     True   \n",
       "20       param-exp-NB-20  MultinomialNB()      bob        True     True   \n",
       "21       param-exp-NB-21  MultinomialNB()      bob        True    False   \n",
       "22       param-exp-NB-22  MultinomialNB()      bob        True    False   \n",
       "23       param-exp-NB-23  MultinomialNB()      bob        True    False   \n",
       "24       param-exp-NB-24  MultinomialNB()      bob        True    False   \n",
       "25       param-exp-NB-25  MultinomialNB()      bob       False     True   \n",
       "26       param-exp-NB-26  MultinomialNB()      bob       False     True   \n",
       "27       param-exp-NB-27  MultinomialNB()      bob       False     True   \n",
       "28       param-exp-NB-28  MultinomialNB()      bob       False     True   \n",
       "29       param-exp-NB-29  MultinomialNB()      bob       False    False   \n",
       "30       param-exp-NB-30  MultinomialNB()      bob       False    False   \n",
       "31       param-exp-NB-31  MultinomialNB()      bob       False    False   \n",
       "32       param-exp-NB-32  MultinomialNB()      bob       False    False   \n",
       "33       param-exp-NB-33  MultinomialNB()      bot        True     True   \n",
       "34       param-exp-NB-34  MultinomialNB()      bot        True     True   \n",
       "35       param-exp-NB-35  MultinomialNB()      bot        True     True   \n",
       "36       param-exp-NB-36  MultinomialNB()      bot        True     True   \n",
       "37       param-exp-NB-37  MultinomialNB()      bot        True    False   \n",
       "38       param-exp-NB-38  MultinomialNB()      bot        True    False   \n",
       "39       param-exp-NB-39  MultinomialNB()      bot        True    False   \n",
       "40       param-exp-NB-40  MultinomialNB()      bot        True    False   \n",
       "41       param-exp-NB-41  MultinomialNB()      bot       False     True   \n",
       "42       param-exp-NB-42  MultinomialNB()      bot       False     True   \n",
       "43       param-exp-NB-43  MultinomialNB()      bot       False     True   \n",
       "44       param-exp-NB-44  MultinomialNB()      bot       False     True   \n",
       "45       param-exp-NB-45  MultinomialNB()      bot       False    False   \n",
       "46       param-exp-NB-46  MultinomialNB()      bot       False    False   \n",
       "47       param-exp-NB-47  MultinomialNB()      bot       False    False   \n",
       "48       param-exp-NB-48  MultinomialNB()      bot       False    False   \n",
       "\n",
       "   remove_stopwords lemmatise  avg_cv_acc      rmse  min_acc  max_acc  \n",
       "0             False     False      0.8290  0.021071    0.785    0.855  \n",
       "1              True      True      0.8245  0.020427    0.775    0.850  \n",
       "2              True     False      0.8245  0.020427    0.775    0.850  \n",
       "3             False      True      0.8245  0.020427    0.775    0.850  \n",
       "4             False     False      0.8245  0.020427    0.775    0.850  \n",
       "5              True      True      0.8245  0.020427    0.775    0.850  \n",
       "6              True     False      0.8245  0.020427    0.775    0.850  \n",
       "7             False      True      0.8245  0.020427    0.775    0.850  \n",
       "8             False     False      0.8245  0.020427    0.775    0.850  \n",
       "9              True      True      0.8090  0.034191    0.745    0.850  \n",
       "10             True     False      0.8090  0.034191    0.745    0.850  \n",
       "11            False      True      0.8090  0.034191    0.745    0.850  \n",
       "12            False     False      0.8090  0.034191    0.745    0.850  \n",
       "13             True      True      0.8090  0.034191    0.745    0.850  \n",
       "14             True     False      0.8090  0.034191    0.745    0.850  \n",
       "15            False      True      0.8090  0.034191    0.745    0.850  \n",
       "16            False     False      0.8090  0.034191    0.745    0.850  \n",
       "17             True      True      0.7610  0.017436    0.745    0.805  \n",
       "18             True     False      0.7610  0.017436    0.745    0.805  \n",
       "19            False      True      0.7610  0.017436    0.745    0.805  \n",
       "20            False     False      0.7610  0.017436    0.745    0.805  \n",
       "21             True      True      0.7610  0.017436    0.745    0.805  \n",
       "22             True     False      0.7610  0.017436    0.745    0.805  \n",
       "23            False      True      0.7610  0.017436    0.745    0.805  \n",
       "24            False     False      0.7610  0.017436    0.745    0.805  \n",
       "25             True      True      0.7415  0.024088    0.700    0.775  \n",
       "26             True     False      0.7415  0.024088    0.700    0.775  \n",
       "27            False      True      0.7415  0.024088    0.700    0.775  \n",
       "28            False     False      0.7415  0.024088    0.700    0.775  \n",
       "29             True      True      0.7415  0.024088    0.700    0.775  \n",
       "30             True     False      0.7415  0.024088    0.700    0.775  \n",
       "31            False      True      0.7415  0.024088    0.700    0.775  \n",
       "32            False     False      0.7415  0.024088    0.700    0.775  \n",
       "33             True      True      0.6755  0.037111    0.610    0.725  \n",
       "34             True     False      0.6755  0.037111    0.610    0.725  \n",
       "35            False      True      0.6755  0.037111    0.610    0.725  \n",
       "36            False     False      0.6755  0.037111    0.610    0.725  \n",
       "37             True      True      0.6755  0.037111    0.610    0.725  \n",
       "38             True     False      0.6755  0.037111    0.610    0.725  \n",
       "39            False      True      0.6755  0.037111    0.610    0.725  \n",
       "40            False     False      0.6755  0.037111    0.610    0.725  \n",
       "41             True      True      0.6670  0.035014    0.590    0.710  \n",
       "42             True     False      0.6670  0.035014    0.590    0.710  \n",
       "43            False      True      0.6670  0.035014    0.590    0.710  \n",
       "44            False     False      0.6670  0.035014    0.590    0.710  \n",
       "45             True      True      0.6670  0.035014    0.590    0.710  \n",
       "46             True     False      0.6670  0.035014    0.590    0.710  \n",
       "47            False      True      0.6670  0.035014    0.590    0.710  \n",
       "48            False     False      0.6670  0.035014    0.590    0.710  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_dataframes['MultinomialNB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "caroline-payment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>learning_model</th>\n",
       "      <th>features</th>\n",
       "      <th>clip_counts</th>\n",
       "      <th>negation</th>\n",
       "      <th>remove_stopwords</th>\n",
       "      <th>lemmatise</th>\n",
       "      <th>avg_cv_acc</th>\n",
       "      <th>rmse</th>\n",
       "      <th>min_acc</th>\n",
       "      <th>max_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline-LR-BoW-clip</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>bow</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.8530</td>\n",
       "      <td>0.021817</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>param-exp-LR-1</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>bow</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.8530</td>\n",
       "      <td>0.021817</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>param-exp-LR-2</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>bow</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.8530</td>\n",
       "      <td>0.021817</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>param-exp-LR-3</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>bow</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.8530</td>\n",
       "      <td>0.021817</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>param-exp-LR-4</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>bow</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.8530</td>\n",
       "      <td>0.021817</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>param-exp-LR-5</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>bow</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.8530</td>\n",
       "      <td>0.021817</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>param-exp-LR-6</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>bow</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.8530</td>\n",
       "      <td>0.021817</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>param-exp-LR-7</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>bow</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.8530</td>\n",
       "      <td>0.021817</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>param-exp-LR-8</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>bow</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.8530</td>\n",
       "      <td>0.021817</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>param-exp-LR-9</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>bow</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.8385</td>\n",
       "      <td>0.017037</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>param-exp-LR-10</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>bow</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.8390</td>\n",
       "      <td>0.019209</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>param-exp-LR-11</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>bow</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.8395</td>\n",
       "      <td>0.019033</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>param-exp-LR-12</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>bow</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.8375</td>\n",
       "      <td>0.017500</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>param-exp-LR-13</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>bow</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.8390</td>\n",
       "      <td>0.019209</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>param-exp-LR-14</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>bow</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.8390</td>\n",
       "      <td>0.019209</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>param-exp-LR-15</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>bow</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.8390</td>\n",
       "      <td>0.019209</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>param-exp-LR-16</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>bow</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.8390</td>\n",
       "      <td>0.019209</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>param-exp-LR-17</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>bob</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.036277</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>param-exp-LR-18</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>bob</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.036277</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>param-exp-LR-19</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>bob</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.036277</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>param-exp-LR-20</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>bob</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.036277</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>param-exp-LR-21</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>bob</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.036277</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>param-exp-LR-22</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>bob</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.036277</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>param-exp-LR-23</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>bob</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.036277</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>param-exp-LR-24</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>bob</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.036277</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>param-exp-LR-25</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>bob</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6335</td>\n",
       "      <td>0.027482</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>param-exp-LR-26</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>bob</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.6335</td>\n",
       "      <td>0.027482</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>param-exp-LR-27</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>bob</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6335</td>\n",
       "      <td>0.027482</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>param-exp-LR-28</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>bob</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.6335</td>\n",
       "      <td>0.027482</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>param-exp-LR-29</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>bob</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6335</td>\n",
       "      <td>0.027482</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>param-exp-LR-30</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>bob</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.6335</td>\n",
       "      <td>0.027482</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>param-exp-LR-31</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>bob</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6335</td>\n",
       "      <td>0.027482</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>param-exp-LR-32</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>bob</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.6335</td>\n",
       "      <td>0.027482</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>param-exp-LR-33</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>bot</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5275</td>\n",
       "      <td>0.013829</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>param-exp-LR-34</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>bot</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.5275</td>\n",
       "      <td>0.013829</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>param-exp-LR-35</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>bot</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5275</td>\n",
       "      <td>0.013829</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>param-exp-LR-36</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>bot</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.5275</td>\n",
       "      <td>0.013829</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>param-exp-LR-37</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>bot</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5275</td>\n",
       "      <td>0.013829</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>param-exp-LR-38</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>bot</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.5275</td>\n",
       "      <td>0.013829</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>param-exp-LR-39</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>bot</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5275</td>\n",
       "      <td>0.013829</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>param-exp-LR-40</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>bot</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.5275</td>\n",
       "      <td>0.013829</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>param-exp-LR-41</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>bot</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5395</td>\n",
       "      <td>0.017812</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>param-exp-LR-42</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>bot</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.5395</td>\n",
       "      <td>0.017812</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>param-exp-LR-43</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>bot</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5395</td>\n",
       "      <td>0.017812</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>param-exp-LR-44</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>bot</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.5395</td>\n",
       "      <td>0.017812</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>param-exp-LR-45</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>bot</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5395</td>\n",
       "      <td>0.017812</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>param-exp-LR-46</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>bot</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.5395</td>\n",
       "      <td>0.017812</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>param-exp-LR-47</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>bot</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5395</td>\n",
       "      <td>0.017812</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>param-exp-LR-48</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>bot</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.5395</td>\n",
       "      <td>0.017812</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name        learning_model features clip_counts negation  \\\n",
       "0   baseline-LR-BoW-clip  LogisticRegression()      bow        True    False   \n",
       "1         param-exp-LR-1  LogisticRegression()      bow        True     True   \n",
       "2         param-exp-LR-2  LogisticRegression()      bow        True     True   \n",
       "3         param-exp-LR-3  LogisticRegression()      bow        True     True   \n",
       "4         param-exp-LR-4  LogisticRegression()      bow        True     True   \n",
       "5         param-exp-LR-5  LogisticRegression()      bow        True    False   \n",
       "6         param-exp-LR-6  LogisticRegression()      bow        True    False   \n",
       "7         param-exp-LR-7  LogisticRegression()      bow        True    False   \n",
       "8         param-exp-LR-8  LogisticRegression()      bow        True    False   \n",
       "9         param-exp-LR-9  LogisticRegression()      bow       False     True   \n",
       "10       param-exp-LR-10  LogisticRegression()      bow       False     True   \n",
       "11       param-exp-LR-11  LogisticRegression()      bow       False     True   \n",
       "12       param-exp-LR-12  LogisticRegression()      bow       False     True   \n",
       "13       param-exp-LR-13  LogisticRegression()      bow       False    False   \n",
       "14       param-exp-LR-14  LogisticRegression()      bow       False    False   \n",
       "15       param-exp-LR-15  LogisticRegression()      bow       False    False   \n",
       "16       param-exp-LR-16  LogisticRegression()      bow       False    False   \n",
       "17       param-exp-LR-17  LogisticRegression()      bob        True     True   \n",
       "18       param-exp-LR-18  LogisticRegression()      bob        True     True   \n",
       "19       param-exp-LR-19  LogisticRegression()      bob        True     True   \n",
       "20       param-exp-LR-20  LogisticRegression()      bob        True     True   \n",
       "21       param-exp-LR-21  LogisticRegression()      bob        True    False   \n",
       "22       param-exp-LR-22  LogisticRegression()      bob        True    False   \n",
       "23       param-exp-LR-23  LogisticRegression()      bob        True    False   \n",
       "24       param-exp-LR-24  LogisticRegression()      bob        True    False   \n",
       "25       param-exp-LR-25  LogisticRegression()      bob       False     True   \n",
       "26       param-exp-LR-26  LogisticRegression()      bob       False     True   \n",
       "27       param-exp-LR-27  LogisticRegression()      bob       False     True   \n",
       "28       param-exp-LR-28  LogisticRegression()      bob       False     True   \n",
       "29       param-exp-LR-29  LogisticRegression()      bob       False    False   \n",
       "30       param-exp-LR-30  LogisticRegression()      bob       False    False   \n",
       "31       param-exp-LR-31  LogisticRegression()      bob       False    False   \n",
       "32       param-exp-LR-32  LogisticRegression()      bob       False    False   \n",
       "33       param-exp-LR-33  LogisticRegression()      bot        True     True   \n",
       "34       param-exp-LR-34  LogisticRegression()      bot        True     True   \n",
       "35       param-exp-LR-35  LogisticRegression()      bot        True     True   \n",
       "36       param-exp-LR-36  LogisticRegression()      bot        True     True   \n",
       "37       param-exp-LR-37  LogisticRegression()      bot        True    False   \n",
       "38       param-exp-LR-38  LogisticRegression()      bot        True    False   \n",
       "39       param-exp-LR-39  LogisticRegression()      bot        True    False   \n",
       "40       param-exp-LR-40  LogisticRegression()      bot        True    False   \n",
       "41       param-exp-LR-41  LogisticRegression()      bot       False     True   \n",
       "42       param-exp-LR-42  LogisticRegression()      bot       False     True   \n",
       "43       param-exp-LR-43  LogisticRegression()      bot       False     True   \n",
       "44       param-exp-LR-44  LogisticRegression()      bot       False     True   \n",
       "45       param-exp-LR-45  LogisticRegression()      bot       False    False   \n",
       "46       param-exp-LR-46  LogisticRegression()      bot       False    False   \n",
       "47       param-exp-LR-47  LogisticRegression()      bot       False    False   \n",
       "48       param-exp-LR-48  LogisticRegression()      bot       False    False   \n",
       "\n",
       "   remove_stopwords lemmatise  avg_cv_acc      rmse  min_acc  max_acc  \n",
       "0             False     False      0.8530  0.021817    0.820    0.900  \n",
       "1              True      True      0.8530  0.021817    0.820    0.900  \n",
       "2              True     False      0.8530  0.021817    0.820    0.900  \n",
       "3             False      True      0.8530  0.021817    0.820    0.900  \n",
       "4             False     False      0.8530  0.021817    0.820    0.900  \n",
       "5              True      True      0.8530  0.021817    0.820    0.900  \n",
       "6              True     False      0.8530  0.021817    0.820    0.900  \n",
       "7             False      True      0.8530  0.021817    0.820    0.900  \n",
       "8             False     False      0.8530  0.021817    0.820    0.900  \n",
       "9              True      True      0.8385  0.017037    0.820    0.870  \n",
       "10             True     False      0.8390  0.019209    0.820    0.880  \n",
       "11            False      True      0.8395  0.019033    0.820    0.880  \n",
       "12            False     False      0.8375  0.017500    0.820    0.870  \n",
       "13             True      True      0.8390  0.019209    0.820    0.880  \n",
       "14             True     False      0.8390  0.019209    0.820    0.880  \n",
       "15            False      True      0.8390  0.019209    0.820    0.880  \n",
       "16            False     False      0.8390  0.019209    0.820    0.880  \n",
       "17             True      True      0.6770  0.036277    0.620    0.740  \n",
       "18             True     False      0.6770  0.036277    0.620    0.740  \n",
       "19            False      True      0.6770  0.036277    0.620    0.740  \n",
       "20            False     False      0.6770  0.036277    0.620    0.740  \n",
       "21             True      True      0.6770  0.036277    0.620    0.740  \n",
       "22             True     False      0.6770  0.036277    0.620    0.740  \n",
       "23            False      True      0.6770  0.036277    0.620    0.740  \n",
       "24            False     False      0.6770  0.036277    0.620    0.740  \n",
       "25             True      True      0.6335  0.027482    0.595    0.675  \n",
       "26             True     False      0.6335  0.027482    0.595    0.675  \n",
       "27            False      True      0.6335  0.027482    0.595    0.675  \n",
       "28            False     False      0.6335  0.027482    0.595    0.675  \n",
       "29             True      True      0.6335  0.027482    0.595    0.675  \n",
       "30             True     False      0.6335  0.027482    0.595    0.675  \n",
       "31            False      True      0.6335  0.027482    0.595    0.675  \n",
       "32            False     False      0.6335  0.027482    0.595    0.675  \n",
       "33             True      True      0.5275  0.013829    0.505    0.545  \n",
       "34             True     False      0.5275  0.013829    0.505    0.545  \n",
       "35            False      True      0.5275  0.013829    0.505    0.545  \n",
       "36            False     False      0.5275  0.013829    0.505    0.545  \n",
       "37             True      True      0.5275  0.013829    0.505    0.545  \n",
       "38             True     False      0.5275  0.013829    0.505    0.545  \n",
       "39            False      True      0.5275  0.013829    0.505    0.545  \n",
       "40            False     False      0.5275  0.013829    0.505    0.545  \n",
       "41             True      True      0.5395  0.017812    0.505    0.565  \n",
       "42             True     False      0.5395  0.017812    0.505    0.565  \n",
       "43            False      True      0.5395  0.017812    0.505    0.565  \n",
       "44            False     False      0.5395  0.017812    0.505    0.565  \n",
       "45             True      True      0.5395  0.017812    0.505    0.565  \n",
       "46             True     False      0.5395  0.017812    0.505    0.565  \n",
       "47            False      True      0.5395  0.017812    0.505    0.565  \n",
       "48            False     False      0.5395  0.017812    0.505    0.565  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_dataframes['LogisticRegression']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "connected-insert",
   "metadata": {},
   "source": [
    "# 3. Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acting-saudi",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'evaluation_dataframes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-89f9ec44ec6a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mevaluation_dataframes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'DecisionTree'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'learning_model'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'features'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'clip_counts'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'negation'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'remove_stopwords'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'lemmatise'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'avg_cv_acc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rmse'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'min_acc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'max_acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlearning_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'evaluation_dataframes' is not defined"
     ]
    }
   ],
   "source": [
    "evaluation_dataframes['DecisionTree'] = pd.DataFrame(columns=['name', 'learning_model', 'features', 'clip_counts', 'negation', 'remove_stopwords', 'lemmatise', 'avg_cv_acc', 'rmse', 'min_acc', 'max_acc'])\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "learning_model = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changing-identifier",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_counts = True\n",
    "negation = False\n",
    "remove_stopwords = False\n",
    "lemmatise = False\n",
    "feature = 'bow' #bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-spine",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
